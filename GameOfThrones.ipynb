{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import codecs\n",
    "import glob\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim.models.word2vec as w2v\n",
    "import sklearn.manifold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/vaibhavgeek/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/vaibhavgeek/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/got1.txt',\n",
       " 'data/got2.txt',\n",
       " 'data/got3.txt',\n",
       " 'data/got4.txt',\n",
       " 'data/got5.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_filenames = sorted(glob.glob(\"data/*.txt\"))\n",
    "book_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'data/got1.txt'...\n",
      "Corpus is now 1611540 characters long\n",
      "\n",
      "Reading 'data/got2.txt'...\n",
      "Corpus is now 3911922 characters long\n",
      "\n",
      "Reading 'data/got3.txt'...\n",
      "Corpus is now 6232286 characters long\n",
      "\n",
      "Reading 'data/got4.txt'...\n",
      "Corpus is now 7948826 characters long\n",
      "\n",
      "Reading 'data/got5.txt'...\n",
      "Corpus is now 9719485 characters long\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_raw = u\"\"\n",
    "for book_filename in book_filenames:\n",
    "    print(\"Reading '{0}'...\".format(book_filename))\n",
    "    with codecs.open(book_filename, \"r\", \"utf-8\") as book_file:\n",
    "        corpus_raw += book_file.read()\n",
    "    print(\"Corpus is now {0} characters long\".format(len(corpus_raw)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_sentences = tokenizer.tokenize(corpus_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for raw_sentence in raw_sentences:\n",
    "    if len(raw_sentence) > 0:\n",
    "        sentences.append(sentence_to_wordlist(raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For information address: Bantam Books.\n"
     ]
    }
   ],
   "source": [
    "print(raw_sentences[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,818,103 \n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in sentences])\n",
    "print(\"{0:,} \".format(token_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(multiprocessing.cpu_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 300\n",
    "min_word_count = 3\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "context_size = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "downsampling = 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-06 15:22:28,674 : INFO : collecting all words and their counts\n",
      "2017-09-06 15:22:28,676 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-09-06 15:22:28,756 : INFO : PROGRESS: at sentence #10000, processed 148061 words, keeping 9326 word types\n",
      "2017-09-06 15:22:28,811 : INFO : PROGRESS: at sentence #20000, processed 302454 words, keeping 13009 word types\n",
      "2017-09-06 15:22:28,856 : INFO : PROGRESS: at sentence #30000, processed 440999 words, keeping 15692 word types\n",
      "2017-09-06 15:22:28,899 : INFO : PROGRESS: at sentence #40000, processed 573069 words, keeping 17519 word types\n",
      "2017-09-06 15:22:28,941 : INFO : PROGRESS: at sentence #50000, processed 700737 words, keeping 18835 word types\n",
      "2017-09-06 15:22:28,994 : INFO : PROGRESS: at sentence #60000, processed 849333 words, keeping 21530 word types\n",
      "2017-09-06 15:22:29,049 : INFO : PROGRESS: at sentence #70000, processed 994857 words, keeping 22882 word types\n",
      "2017-09-06 15:22:29,100 : INFO : PROGRESS: at sentence #80000, processed 1135734 words, keeping 24089 word types\n",
      "2017-09-06 15:22:29,149 : INFO : PROGRESS: at sentence #90000, processed 1275679 words, keeping 25810 word types\n",
      "2017-09-06 15:22:29,208 : INFO : PROGRESS: at sentence #100000, processed 1410194 words, keeping 26714 word types\n",
      "2017-09-06 15:22:29,274 : INFO : PROGRESS: at sentence #110000, processed 1553943 words, keeping 27664 word types\n",
      "2017-09-06 15:22:29,339 : INFO : PROGRESS: at sentence #120000, processed 1694378 words, keeping 28414 word types\n",
      "2017-09-06 15:22:29,390 : INFO : collected 29026 word types from a corpus of 1818103 raw words and 128867 sentences\n",
      "2017-09-06 15:22:29,391 : INFO : Loading a fresh vocabulary\n",
      "2017-09-06 15:22:29,464 : INFO : min_count=3 retains 17277 unique words (59% of original 29026, drops 11749)\n",
      "2017-09-06 15:22:29,465 : INFO : min_count=3 leaves 1802699 word corpus (99% of original 1818103, drops 15404)\n",
      "2017-09-06 15:22:29,548 : INFO : deleting the raw counts dictionary of 29026 items\n",
      "2017-09-06 15:22:29,551 : INFO : sample=0.001 downsamples 50 most-common words\n",
      "2017-09-06 15:22:29,552 : INFO : downsampling leaves estimated 1404424 word corpus (77.9% of prior 1802699)\n",
      "2017-09-06 15:22:29,553 : INFO : estimated required memory for 17277 words and 300 dimensions: 50103300 bytes\n",
      "2017-09-06 15:22:29,622 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "thrones2vec.build_vocab(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17277"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thrones2vec.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec vocabulary length: 17277\n"
     ]
    }
   ],
   "source": [
    "print(\"Word2Vec vocabulary length:\", len(thrones2vec.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-06 15:22:52,251 : INFO : training model with 4 workers on 17277 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=7\n",
      "2017-09-06 15:22:53,405 : INFO : PROGRESS: at 10.99% examples, 146710 words/s, in_qsize 8, out_qsize 0\n",
      "2017-09-06 15:22:54,437 : INFO : PROGRESS: at 22.14% examples, 151770 words/s, in_qsize 8, out_qsize 0\n",
      "2017-09-06 15:22:55,550 : INFO : PROGRESS: at 35.01% examples, 152140 words/s, in_qsize 8, out_qsize 0\n",
      "2017-09-06 15:22:56,583 : INFO : PROGRESS: at 46.55% examples, 153305 words/s, in_qsize 8, out_qsize 0\n",
      "2017-09-06 15:22:57,637 : INFO : PROGRESS: at 57.85% examples, 153571 words/s, in_qsize 8, out_qsize 0\n",
      "2017-09-06 15:22:58,655 : INFO : PROGRESS: at 70.02% examples, 155649 words/s, in_qsize 8, out_qsize 0\n",
      "2017-09-06 15:22:59,656 : INFO : PROGRESS: at 82.34% examples, 157480 words/s, in_qsize 8, out_qsize 0\n",
      "2017-09-06 15:23:00,759 : INFO : PROGRESS: at 94.47% examples, 157081 words/s, in_qsize 8, out_qsize 0\n",
      "2017-09-06 15:23:01,037 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-09-06 15:23:01,126 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-09-06 15:23:01,147 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-09-06 15:23:01,194 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-09-06 15:23:01,195 : INFO : training on 1818103 raw words (1405068 effective words) took 8.9s, 158076 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1405068"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.train(sentences, total_examples=128867, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128867"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thrones2vec.most_similar(\"direwolf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thrones2vec.most_similar(\"stark\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thrones2vec.most_similar(\"Winterfell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thrones2vec.most_similar(\"Stark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thrones2vec.most_similar(\"King\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thrones2vec.most_similar(\"Dragons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"trained\"):\n",
    "    os.makedirs(\"trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thrones2vec.save(os.path.join(\"trained\", \"thrones2vec.w2v\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne = sklearn.manifold.TSNE(n_components=2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_word_vectors_matrix = thrones2vec.wv.syn0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nearest_similarity_cosmul(start1, end1, end2):\n",
    "    similarities = thrones2vec.most_similar_cosmul(\n",
    "        positive=[end2, start1],\n",
    "        negative=[end1]\n",
    "    )\n",
    "    start2 = similarities[0][0]\n",
    "    print(\"{start1} is related to {end1}, as {start2} is related to {end2}\".format(**locals()))\n",
    "    return start2                                                                                                                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "       nearest_similarity_cosmul(\"Stark\", \"Winterfell\", \"Riverrun\")\n",
    "                                                                                                                                                                                                                                                                                                                                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nearest_similarity_cosmul(\"Tyrion\", \"wine\", \"Jaime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nearest_similarity_cosmul(\"Arya\", \"Nymeria\", \"dragons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne = sklearn.manifold.TSNE(n_components=2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
